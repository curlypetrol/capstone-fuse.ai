{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Our first model is a logistic regression classifier. This notebook execution lasts around 20 minutes, mainly due to the Grid Seach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, balanced_accuracy_score, make_scorer, classification_report\n",
    "import pyprojroot\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = pyprojroot.here().joinpath('data', 'fetal_health.csv')\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference(['fetal_health', 'fetal_health_label'])]\n",
    "y = df['fetal_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, stratify = y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'balanced_accuracy': balanced_accuracy_score, \n",
    "    'recall': lambda y_true, y_pred: recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'precision': lambda y_true, y_pred: precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'f1_score': lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "for key in metrics.keys():\n",
    "    metrics[key] = make_scorer(metrics[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tune our hyperparameters with GridSearchCV, which conducts an exhaustive search over specified parameter values of an estimator. It optimizes the specified metric, balanced accuracy in this case, with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our parameters dictionary\n",
    "params = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"],\n",
    "    \"C\": np.logspace(-6, 6, 101),\n",
    "    \"random_state\": [RANDOM_STATE],\n",
    "    \"max_iter\": [1_000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Grid Search\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=params, scoring=metrics[\"balanced_accuracy\"],\\\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE))\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Save results in dataframe for visualization\n",
    "grid_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.787974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.57544</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.787449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.758578</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.784489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>2.290868</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.783851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.737801</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.782862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.318257</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.782192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.781786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>2.290868</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.781535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>2.290868</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.781535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2.290868</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.781535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>3.019952</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.780596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.780257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>3.019952</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.780043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.779903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.331131</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.779365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>2.290868</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.779356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.331131</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.779315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.331131</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.779315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.331131</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.779315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.331131</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.779315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_penalty param_solver   param_C param_random_state param_max_iter  \\\n",
       "1133            l1         saga  0.436516                 11           1000   \n",
       "1157            l1         saga   0.57544                 11           1000   \n",
       "1181            l1         saga  0.758578                 11           1000   \n",
       "1277            l1         saga  2.290868                 11           1000   \n",
       "1253            l1         saga  1.737801                 11           1000   \n",
       "1229            l1         saga  1.318257                 11           1000   \n",
       "1205            l1         saga       1.0                 11           1000   \n",
       "1282            l2          sag  2.290868                 11           1000   \n",
       "1280            l2    newton-cg  2.290868                 11           1000   \n",
       "1278            l2        lbfgs  2.290868                 11           1000   \n",
       "1307            l2         saga  3.019952                 11           1000   \n",
       "1331            l2         saga  3.981072                 11           1000   \n",
       "1301            l1         saga  3.019952                 11           1000   \n",
       "1085            l1         saga  0.251189                 11           1000   \n",
       "1109            l1         saga  0.331131                 11           1000   \n",
       "1283            l2         saga  2.290868                 11           1000   \n",
       "1114            l2          sag  0.331131                 11           1000   \n",
       "1115            l2         saga  0.331131                 11           1000   \n",
       "1110            l2        lbfgs  0.331131                 11           1000   \n",
       "1112            l2    newton-cg  0.331131                 11           1000   \n",
       "\n",
       "      mean_test_score  \n",
       "1133         0.787974  \n",
       "1157         0.787449  \n",
       "1181         0.784489  \n",
       "1277         0.783851  \n",
       "1253         0.782862  \n",
       "1229         0.782192  \n",
       "1205         0.781786  \n",
       "1282         0.781535  \n",
       "1280         0.781535  \n",
       "1278         0.781535  \n",
       "1307         0.780596  \n",
       "1331         0.780257  \n",
       "1301         0.780043  \n",
       "1085         0.779903  \n",
       "1109         0.779365  \n",
       "1283         0.779356  \n",
       "1114         0.779315  \n",
       "1115         0.779315  \n",
       "1110         0.779315  \n",
       "1112         0.779315  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results are given such that each row corresponds to grid search iteration.\n",
    "# Here we extract only the columns that contain the parameters used for the iteration\n",
    "# and the mean test score.\n",
    "sum_cols = [f\"param_{param}\" for param in list(params.keys())]\n",
    "sum_cols.append('mean_test_score')\n",
    "grid_df[sum_cols].sort_values(by=\"mean_test_score\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the best estimator found by the algorithm to run a more rigorous evaluation of the model over a larger set of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.43651583224016566, max_iter=1000, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=11, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.43651583224016566, max_iter=1000, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=11, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.43651583224016566, max_iter=1000, penalty='l1',\n",
       "                   random_state=11, solver='saga')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_clf = grid_search.best_estimator_\n",
    "log_reg_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using cross validation to precisely evaluate model performance, independent from random data partitions, which may influence our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joselier/miniconda3/envs/capstone-project/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/joselier/miniconda3/envs/capstone-project/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/joselier/miniconda3/envs/capstone-project/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/joselier/miniconda3/envs/capstone-project/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/joselier/miniconda3/envs/capstone-project/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv_result = cross_validate(log_reg_clf, X_test, y_test, scoring=metrics,\\\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE), return_estimator=True)\n",
    "cv_result_df = pd.DataFrame(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                  0.355753\n",
       "score_time                0.010324\n",
       "test_accuracy             0.866445\n",
       "test_balanced_accuracy    0.689822\n",
       "test_recall               0.689822\n",
       "test_precision            0.741956\n",
       "test_f1_score             0.700151\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df = cv_result_df.drop('estimator', axis=1)\n",
    "cv_result_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that dummy classifier has very low performance. These will be our baseline metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1, 2, 3]\n",
    "target_names = ['Normal', 'Suspect', 'Pathological']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.93      0.93      0.93       332\n",
      "     Suspect       0.61      0.66      0.63        59\n",
      "Pathological       0.90      0.77      0.83        35\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.81      0.79      0.80       426\n",
      "weighted avg       0.89      0.88      0.88       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, labels=labels, target_names=target_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see in more detail our metrics calculated per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the _pickle_ library for saving our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = pyprojroot.here().joinpath('models', 'log_reg_clf.pkl')\n",
    "\n",
    "# Save the model\n",
    "with open(MODEL_PATH,'wb') as f:\n",
    "    pickle.dump(grid_search.best_estimator_, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
